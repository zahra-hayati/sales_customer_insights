{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedd778f",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e9d33",
   "metadata": {},
   "source": [
    "### Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc91be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'figure.dpi': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5a38e",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../data/sales_data.csv')\n",
    "products = pd.read_csv('../data/product_info.csv')\n",
    "customers = pd.read_csv('../data/customer_info.csv')\n",
    "\n",
    "print(f\"Sales:, {sales.shape}\")\n",
    "print(f\"Products:, {products.shape}\")\n",
    "print(f\"Customers:, {customers.shape}\")\n",
    "\n",
    "display(sales)\n",
    "display(products)\n",
    "display(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f67736",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in [(sales, 'sales'), (products, 'products'), (customers, 'customers')]:\n",
    "    print(\"=== \", name, \" ===\")\n",
    "    display(df.info())\n",
    "    display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec242261",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e6690",
   "metadata": {},
   "source": [
    "#### Trim whitespace everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_all_str_cols(df):\n",
    "    for c in df.select_dtypes(include='object').columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "        df.loc[df[c].isin(['nan', 'None', 'NoneType']), c] = np.nan\n",
    "    return df\n",
    "\n",
    "sales = strip_all_str_cols(sales)\n",
    "products = strip_all_str_cols(products)\n",
    "customers = strip_all_str_cols(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4f594",
   "metadata": {},
   "source": [
    "#### Fix numeric columns in sales: quantity, unit_price, discount_applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b7cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['quantity'] = sales['quantity'].replace({'three': '3', 'five': '5'}).astype(object)\n",
    "\n",
    "sales['quantity'] = pd.to_numeric(sales['quantity'], errors='coerce')\n",
    "sales['unit_price'] = pd.to_numeric(sales['unit_price'], errors='coerce')\n",
    "sales['discount_applied'] = pd.to_numeric(sales['discount_applied'], errors='coerce')\n",
    "\n",
    "sales['quantity_imputed_flag'] = sales['quantity'].isnull()\n",
    "\n",
    "sales.loc[sales['quantity'].isnull(), 'quantity'] = 1\n",
    "sales['quantity'] = sales['quantity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a94b3a",
   "metadata": {},
   "source": [
    "#### Dates parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['order_date'] = pd.to_datetime(\n",
    "    sales['order_date'], \n",
    "    format='%d-%m-%Y', \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "products['launch_date'] = pd.to_datetime(\n",
    "    products['launch_date'], \n",
    "    format='%d-%m-%y', \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "customers['signup_date'] = pd.to_datetime(\n",
    "    customers['signup_date'], \n",
    "    format='%d-%m-%y', \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "print(\"order_date parse nulls:\", sales['order_date'].isna().sum())\n",
    "print(\"launch_date parse nulls:\", products['launch_date'].isna().sum())\n",
    "print(\"signup_date parse nulls:\", customers['signup_date'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6ff1b",
   "metadata": {},
   "source": [
    "#### Canonicalize and clean text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b89216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_delivery(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if 'deliver' in s: return 'Delivered'\n",
    "    if 'delay' in s or 'dely' in s: return 'Delayed'\n",
    "    if 'cancel' in s: return 'Cancelled'\n",
    "    return 'Other'\n",
    "\n",
    "sales['delivery_status'] = sales['delivery_status'].apply(clean_delivery)\n",
    "\n",
    "pm_map = {\n",
    "    'credit card': 'Credit Card',\n",
    "    'bank transfr': 'Bank Transfer',\n",
    "}\n",
    "sales['payment_method'] = sales['payment_method'].str.strip().str.lower().map(pm_map).fillna(sales['payment_method'].str.title())\n",
    "\n",
    "sales['region'] = sales['region'].replace({'nrth': 'North'}).str.title()\n",
    "\n",
    "customers['region'] = customers['region'].replace({'nrth': 'North'}).str.title()\n",
    "\n",
    "def clean_loyalty(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if 'gold' in s or s in ('gld',): return 'Gold'\n",
    "    if 'silver' in s or s in ('sllver',): return 'Silver'\n",
    "    if 'bronze' in s or s in ('brnze',): return 'Bronze'\n",
    "    return 'Other'\n",
    "\n",
    "customers['loyalty_tier'] = customers['loyalty_tier'].apply(clean_loyalty)\n",
    "\n",
    "def clean_gender(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    if s.startswith('f'): return 'Female'\n",
    "    if s.startswith('m'): return 'Male'\n",
    "    return 'Other'\n",
    "\n",
    "customers['gender'] = customers['gender'].apply(clean_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610506e0",
   "metadata": {},
   "source": [
    "#### Handle missing product_id / customer_id / discount_applied / email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['product_id'] = sales['product_id'].fillna('UNKNOWN_PRODUCT')\n",
    "sales['customer_id'] = sales['customer_id'].fillna('UNKNOWN_CUSTOMER')\n",
    "\n",
    "sales['discount_imputed_flag'] = sales['discount_applied'].isna()\n",
    "sales['discount_applied'] = sales['discount_applied'].fillna(0.0)\n",
    "\n",
    "customers['email'] = customers['email'].replace({'nan': np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac7b576",
   "metadata": {},
   "source": [
    "#### Handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['synthetic_order_key'] = (\n",
    "    sales['order_id'].astype(str) + '_' +\n",
    "    sales['customer_id'].astype(str) + '_' +\n",
    "    sales['product_id'].astype(str)\n",
    ")\n",
    "\n",
    "sales['order_id_duplicate_flag'] = sales.duplicated(subset=['order_id'], keep=False)\n",
    "\n",
    "conflicting_orders = (\n",
    "    sales.groupby('order_id')\n",
    "    .agg({'customer_id':'nunique', 'order_date':'nunique'})\n",
    "    .query('customer_id > 1 or order_date > 1')\n",
    ")\n",
    "print(\"Conflicting order_ids:\\n\", conflicting_orders)\n",
    "\n",
    "sales = sales.dropna(subset=['order_id', 'product_id', 'customer_id'])\n",
    "customers = customers.dropna(subset=['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_sales = sales[sales.isnull().any(axis=1)]\n",
    "print(f\"Sales rows with missing values: {len(missing_sales)}\")\n",
    "display(missing_sales)\n",
    "\n",
    "missing_customers = customers[customers.isnull().any(axis=1)]\n",
    "print(f\"Customer rows with missing values: {len(missing_customers)}\")\n",
    "display(missing_customers)\n",
    "\n",
    "\n",
    "missing_products = products[products.isnull().any(axis=1)]\n",
    "print(f\"Product rows with missing values: {len(missing_products)}\")\n",
    "display(missing_products)\n",
    "\n",
    "sales_dupes_order = sales[sales.duplicated(subset=['order_id'], keep=False)]\n",
    "print(\"Duplicate order_ids:\", len(sales_dupes_order))\n",
    "display(sales_dupes_order)\n",
    "\n",
    "sales_dupes_line = sales[sales.duplicated(subset=['order_id','product_id'], keep=False)]\n",
    "print(\"Duplicate order lines:\", len(sales_dupes_line))\n",
    "display(sales_dupes_line)\n",
    "\n",
    "customers_dupes = customers[customers.duplicated(subset=['customer_id'], keep=False)]\n",
    "print(\"Duplicate customer_ids:\", len(customers_dupes))\n",
    "display(customers_dupes)\n",
    "\n",
    "products_dupes = products[products.duplicated(subset=['product_id'], keep=False)]\n",
    "print(\"Duplicate product_ids:\", len(products_dupes))\n",
    "display(products_dupes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96851b49",
   "metadata": {},
   "source": [
    "#### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(sales: pd.DataFrame, customers: pd.DataFrame, products: pd.DataFrame):\n",
    "    sales = sales.dropna(subset=['order_id', 'product_id', 'customer_id']).copy()\n",
    "    customers = customers.dropna(subset=['customer_id']).copy()\n",
    "    products = products.dropna(subset=['product_id']).copy()\n",
    "\n",
    "    sales['was_price_imputed'] = sales['unit_price'].isna()\n",
    "    sales['was_qty_imputed'] = sales['quantity'].isna()\n",
    "    sales['was_status_imputed'] = sales['delivery_status'].isna()\n",
    "    sales['was_payment_imputed'] = sales['payment_method'].isna()\n",
    "    sales['was_order_date_imputed'] = sales['order_date'].isna()\n",
    "    customers['was_region_imputed'] = customers['region'].isna()\n",
    "    customers['was_tier_imputed'] = customers['loyalty_tier'].isna()\n",
    "    customers['was_gender_imputed'] = customers['gender'].isna()\n",
    "    customers['was_signup_date_imputed'] = customers['signup_date'].isna()\n",
    "\n",
    "    # Fill unit_price using product base price\n",
    "    if 'base_price' in products.columns:\n",
    "        price_map = products.set_index('product_id')['base_price']\n",
    "        sales['unit_price'] = sales['unit_price'].fillna(sales['product_id'].map(price_map))\n",
    "\n",
    "    # Fill quantity with median\n",
    "    if sales['quantity'].isna().any():\n",
    "        sales['quantity'].fillna(sales['quantity'].median(), inplace=True)\n",
    "\n",
    "    # Fill delivery_status and payment_method\n",
    "    if sales['delivery_status'].isna().any():\n",
    "        sales['delivery_status'] = sales.groupby('region')['delivery_status'].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x.fillna('Unknown')\n",
    "        )\n",
    "    sales['payment_method'] = sales['payment_method'].fillna('Unknown')\n",
    "\n",
    "    if sales['order_date'].isna().any():\n",
    "        median_order_date = sales['order_date'].median()\n",
    "        sales['order_date'] = sales['order_date'].fillna(median_order_date)\n",
    "\n",
    "    # Fill region based on loyalty_tier mode\n",
    "    if customers['region'].isna().any():\n",
    "        customers['region'] = customers.groupby('loyalty_tier')['region'].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x.fillna(customers['region'].mode()[0])\n",
    "        )\n",
    "\n",
    "    customers['region'] = customers['region'].fillna(customers['region'].mode()[0])\n",
    "\n",
    "    if 'total_spent' not in customers.columns:\n",
    "        customers['total_spent'] = np.nan\n",
    "\n",
    "\n",
    "    spend_map = sales.groupby('customer_id')['unit_price'].sum()\n",
    "    customers['total_spent'] = customers['total_spent'].fillna(customers['customer_id'].map(spend_map))\n",
    "\n",
    "    customers['total_spent'] = customers['total_spent'].fillna(0)\n",
    "\n",
    "\n",
    "    # Assign based on spend thresholds\n",
    "    tier_values = np.select(\n",
    "        [\n",
    "            customers['total_spent'] > 5000,\n",
    "            customers['total_spent'] > 2000,\n",
    "            customers['total_spent'] > 500,\n",
    "        ],\n",
    "        ['Gold', 'Silver', 'Bronze'],\n",
    "        default='Bronze'\n",
    "    )\n",
    "\n",
    "    customers.loc[customers['loyalty_tier'].isna(), 'loyalty_tier'] = tier_values[customers['loyalty_tier'].isna()]\n",
    "\n",
    "    customers['loyalty_tier'] = customers['loyalty_tier'].fillna(customers['loyalty_tier'].mode()[0])\n",
    "\n",
    "\n",
    "    # Gender imputation\n",
    "    if 'gender' in customers.columns:\n",
    "        customers['gender'] = customers['gender'].fillna(customers['gender'])\n",
    "\n",
    "    # Infer from region\n",
    "    customers['gender'] = customers.groupby('region')['gender'].transform(\n",
    "        lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x\n",
    "    )\n",
    "\n",
    "    customers['gender'] = customers['gender'].fillna(customers['gender'].mode()[0])\n",
    "\n",
    "    # Fill email and signup_date\n",
    "    customers['email'] = customers['email'].fillna('unknown@sellers.com')\n",
    "\n",
    "    if customers['signup_date'].isna().any():\n",
    "        median_signup = customers['signup_date'].median()\n",
    "        customers['signup_date'] = customers['signup_date'].fillna(median_signup)\n",
    "\n",
    "\n",
    "    return (\n",
    "        sales.reset_index(drop=True),\n",
    "        customers.reset_index(drop=True),\n",
    "        products.reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "sales, customers, products = clean_data(sales, customers, products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01f9b9",
   "metadata": {},
   "source": [
    "#### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b88f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = sales.merge(products.add_prefix('prod_'), left_on='product_id', right_on='prod_product_id', how='left')\n",
    "merged = merged.merge(customers.add_prefix('cust_'), left_on='customer_id', right_on='cust_customer_id', how='left')\n",
    "\n",
    "print('Merged shape:', merged.shape)\n",
    "merged.info()\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f81807",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue\n",
    "merged['unit_price'] = merged['unit_price'].astype(float)\n",
    "merged['revenue'] = merged['quantity'] * merged['unit_price'] * (1 - merged['discount_applied'])\n",
    "\n",
    "# order_week\n",
    "merged['order_week'] = merged['order_date'].dt.isocalendar().week\n",
    "\n",
    "# price_band\n",
    "merged['price_band'] = pd.cut(merged['unit_price'], bins=[-1, 15, 30, np.inf], labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# days_to_order\n",
    "merged['launch_date'] = merged['prod_launch_date']\n",
    "merged['days_to_order'] = (merged['order_date'] - merged['launch_date']).dt.days\n",
    "merged['days_to_order_flag'] = (merged['days_to_order'] < 0) | (merged['days_to_order'] > 365)\n",
    "\n",
    "# email_domain\n",
    "merged['email_domain'] = merged['cust_email'].fillna('').str.extract(r'@(.+)$', expand=False).fillna('unknown')\n",
    "\n",
    "# is_late\n",
    "merged['is_late'] = merged['delivery_status'] == 'Delayed'\n",
    "\n",
    "merged_df = merged.copy()\n",
    "\n",
    "print('merged_df shape:', merged_df.shape)\n",
    "merged_df.info()\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b1617",
   "metadata": {},
   "source": [
    "#### Summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly revenue trends by region\n",
    "weekly = merged_df.groupby(['order_week','region']).agg(\n",
    "    weekly_revenue=('revenue','sum')\n",
    ").reset_index()\n",
    "pivot_week_region = weekly.pivot(index='order_week', columns='region', values='weekly_revenue').fillna(0)\n",
    "display(pivot_week_region)\n",
    "\n",
    "# Product category performance\n",
    "cat_perf = merged_df.groupby('prod_category').agg(\n",
    "    total_revenue=('revenue','sum'),\n",
    "    total_quantity=('quantity','sum'),\n",
    "    avg_discount=('discount_applied','mean')\n",
    ").sort_values('total_revenue', ascending=False).reset_index()\n",
    "display(cat_perf)\n",
    "\n",
    "# Customer behaviour by loyalty tier and signup month\n",
    "merged_df['signup_month'] = merged_df['cust_signup_date'].dt.to_period('M')\n",
    "cust_behaviour = merged_df.groupby(['cust_loyalty_tier','signup_month']).agg(\n",
    "    revenue=('revenue','sum'),\n",
    "    orders=('order_id','nunique'),\n",
    "    avg_order_value=('revenue','mean')\n",
    ").reset_index()\n",
    "display(cust_behaviour)\n",
    "\n",
    "# Delivery performance by region and price band\n",
    "delivery_perf = merged_df.groupby(['region','price_band'], observed=True).agg(\n",
    "    total_orders=('order_id','count'),\n",
    "    delayed_pct=('is_late',lambda x: 100*x.sum()/len(x))\n",
    ").reset_index()\n",
    "display(delivery_perf)\n",
    "\n",
    "# Preferred payment methods by loyalty tier\n",
    "pay_pref = merged_df.groupby(['cust_loyalty_tier','payment_method']).size().reset_index(name='count')\n",
    "pay_pref = pay_pref.sort_values(['cust_loyalty_tier','count'], ascending=[True,False])\n",
    "display(pay_pref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5125f4b",
   "metadata": {},
   "source": [
    "#### Visual Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76809cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Line plot - weekly revenue trends by region\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for col in pivot_week_region.columns:\n",
    "    ax.plot(pivot_week_region.index, pivot_week_region[col], marker='o', label=col)\n",
    "ax.set_title('Weekly Revenue Trends by Region', fontsize=14)\n",
    "ax.set_xlabel('ISO Week', fontsize=12)\n",
    "ax.set_ylabel('Revenue (£)', fontsize=12)\n",
    "ax.legend(title='Region')\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. Bar chart - top 5 categories by revenue\n",
    "top5 = cat_perf.head(5)\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "sns.barplot(x='prod_category', y='total_revenue', hue='prod_category', data=top5, ax=ax, palette='viridis', dodge=False, legend=False)\n",
    "ax.set_title('Top 5 Product Categories by Revenue', fontsize=14)\n",
    "ax.set_ylabel('Revenue (£)', fontsize=12)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "for i, v in enumerate(top5['total_revenue']):\n",
    "    ax.text(i, v + 10, f\"{v:.0f}\", ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3. Boxplot - quantity vs discount across categories\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(x='prod_category', y='quantity', data=merged_df, ax=ax)\n",
    "ax.set_title('Quantity Distribution by Product Category', fontsize=14)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Quantity', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 4. Heatmap - correlation between revenue, discount, quantity\n",
    "corr_df = merged_df[['revenue','discount_applied','quantity']].corr()\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.heatmap(corr_df, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n",
    "ax.set_title('Correlation Matrix: Revenue, Discount, Quantity', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 5. Countplot - orders by loyalty tier with hue = region\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "sns.countplot(x='cust_loyalty_tier', hue='region', data=merged_df, palette='Set2', ax=ax)\n",
    "ax.set_title('Orders by Loyalty Tier and Region', fontsize=14)\n",
    "ax.set_xlabel('Loyalty Tier', fontsize=12)\n",
    "ax.set_ylabel('Number of Orders', fontsize=12)\n",
    "plt.legend(title='Region')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6. Stacked bar - delivery status by price band\n",
    "ds = merged_df.groupby(['price_band','delivery_status'], observed=True).size().unstack(fill_value=0)\n",
    "ds.plot(kind='bar', stacked=True, figsize=(8,5), colormap='Pastel1')\n",
    "plt.title('Delivery Status by Price Band', fontsize=14)\n",
    "plt.xlabel('Price Band')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Delivery Status')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['cust_signup_date'] = pd.to_datetime(merged_df['cust_signup_date'], errors='coerce')\n",
    "\n",
    "merged_df['signup_month'] = merged_df['cust_signup_date'].dt.to_period('M').astype(str)\n",
    "\n",
    "signup_tier = (\n",
    "    merged_df.groupby(['signup_month', 'cust_loyalty_tier'], observed=True)\n",
    "    .agg(total_revenue=('revenue', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(signup_tier)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(x='signup_month', y='total_revenue', hue='cust_loyalty_tier', data=signup_tier, marker='o')\n",
    "plt.title('Revenue by Signup Month and Loyalty Tier')\n",
    "plt.xlabel('Signup Month')\n",
    "plt.ylabel('Total Revenue (£)')\n",
    "plt.legend(title='Loyalty Tier')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca3a47",
   "metadata": {},
   "source": [
    "#### Stretch Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e09888",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_customers = merged_df.query(\n",
    "    \"'2025-04-01' <= cust_signup_date <= '2025-06-30'\"\n",
    ")['cust_customer_id'].unique()\n",
    "\n",
    "q2_sales = merged_df[merged_df['cust_customer_id'].isin(q2_customers)].copy()\n",
    "q2_sales['days_since_signup'] = (q2_sales['order_date'] - q2_sales['cust_signup_date']).dt.days\n",
    "\n",
    "early_orders = q2_sales.query('0 <= days_since_signup <= 14')\n",
    "\n",
    "high_discount_early = early_orders.query('discount_applied >= 0.20')\n",
    "\n",
    "print(f\"Q2 signups: {len(q2_customers)} customers\")\n",
    "print(f\"Ordered in ≤14 days: {early_orders['cust_customer_id'].nunique()} customers\")\n",
    "print(f\"With ≥20% discount: {high_discount_early.shape[0]} orders\")\n",
    "\n",
    "stretch_result = high_discount_early[['order_id', 'cust_customer_id', 'order_date', \n",
    "                                      'cust_signup_date', 'days_since_signup', \n",
    "                                      'discount_applied', 'revenue', 'prod_product_name']]\n",
    "display(stretch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bb45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "merged_df['revenue_norm'] = scaler.fit_transform(merged_df[['revenue']])\n",
    "merged_df['unit_price_norm'] = scaler.fit_transform(merged_df[['unit_price']])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.histplot(merged_df['revenue_norm'], kde=True, ax=axes[0], color='teal')\n",
    "axes[0].set_title('Normalized Revenue Distribution')\n",
    "sns.histplot(merged_df['unit_price_norm'], kde=True, ax=axes[1], color='coral')\n",
    "axes[1].set_title('Normalized Unit Price Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ff2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_metrics = (\n",
    "    merged_df.groupby('product_id')\n",
    "    .agg(\n",
    "        total_qty=('quantity', 'sum'),\n",
    "        avg_discount=('discount_applied', 'mean'),\n",
    "        delayed_rate=('is_late', 'mean'),\n",
    "        total_orders=('order_id', 'count'),\n",
    "        total_revenue=('revenue', 'sum')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "product_metrics = product_metrics.merge(\n",
    "    products[['product_id', 'product_name', 'category']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "qty_threshold = product_metrics['total_qty'].quantile(0.25)\n",
    "print(f\"25th percentile quantity: {qty_threshold:.1f}\")\n",
    "\n",
    "product_metrics['low_quantity'] = product_metrics['total_qty'] < qty_threshold\n",
    "product_metrics['high_discount'] = product_metrics['avg_discount'] > 0.15\n",
    "product_metrics['high_delay'] = product_metrics['delayed_rate'] > 0.30\n",
    "\n",
    "product_metrics['underperf_score'] = (\n",
    "    product_metrics['low_quantity'].astype(int) +\n",
    "    product_metrics['high_discount'].astype(int) +\n",
    "    product_metrics['high_delay'].astype(int)\n",
    ")\n",
    "\n",
    "underperformers = product_metrics[product_metrics['underperf_score'] >= 2].copy()\n",
    "\n",
    "print(f\"\\nUnderperforming products: {len(underperformers)}\")\n",
    "display(\n",
    "    underperformers[['product_name', 'category', 'total_qty', 'avg_discount', \n",
    "                     'delayed_rate', 'underperf_score', 'total_revenue']]\n",
    "    .sort_values('underperf_score', ascending=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
